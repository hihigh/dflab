<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- viewport for mobile device / REF : http://aboooks.tistory.com/352 -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>webRTC - audio</title>

    <!-- PWA -->
    <meta name="mobile-web-app-capable" content="yes">
    <link rel="manifest" href="http://dev.designfever.com/lab/manifest.json">

    <link rel="stylesheet" href="css/normalize.css">
    <link rel="stylesheet" href="css/base.css">
    <link rel="stylesheet" href="css/frame.css">

    <script src="js/common.bundle.js"></script>
    <!--<link rel="stylesheet" href="css/main.css">-->
</head>

<style>

    #container {
        width: 100%;
        padding-top: 40px;

    }

    #container div{
        width: 100%;
        padding: 30px;
        font-size: 40px;
    }

    .value {display: inline-block}

    .des {padding: 30px; font-size: 14px; line-height: 20px}

    .hide {display: none}

    .outlink {position:absolute; font-size: 12px; right: 30px; opacity: 0.5; margin-top: 40px}


</style>

<body>


<div id="app" class="app-container site-wrapper">
    <comp-frame :root-path="'http://dev.designfever.com/lab/'"
                :active-id="'id_etc_WebRTCAudioTest'"
                :is-white-mode="false"
                :content-info-title="'WebRTC - Audio'"
                :content-info-description="'Audio Test in Mobile Device'"
                :content-info-manual="''"
    ></comp-frame>
    <div id="container">
        <div id="instant">Instant : <p class="value">0</p></div>
        <div id="slow">Slow : <p class="value">0</p></div>
        <div id="clip">Clip : <p class="value">0</p></div>
        <p class="des">The 'instant' volume changes approximately every 50ms; the 'slow' volume approximates the average volume over about a second.</p>
        <a href="https://webrtc.github.io/samples/src/content/getusermedia/volume/" class="outlink">go webrtc.github.io</a>
    </div>
</div>

<script src="js/frame_main.bundle.js"></script>
<script>
    window.initVue();
</script>




<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>

<!--  soundmeter.js  -->
<!--  https://webrtc.github.io/samples/src/content/getusermedia/volume/  -->
<script>
    function SoundMeter(context) {
        this.context = context;
        this.instant = 0.0;
        this.slow = 0.0;
        this.clip = 0.0;
        this.script = context.createScriptProcessor(2048, 1, 1);
        var that = this;
        this.script.onaudioprocess = function(event) {
            var input = event.inputBuffer.getChannelData(0);
            var i;
            var sum = 0.0;
            var clipcount = 0;
            for (i = 0; i < input.length; ++i) {
                sum += input[i] * input[i];
                if (Math.abs(input[i]) > 0.99) {
                    clipcount += 1;
                }
            }
            that.instant = Math.sqrt(sum / input.length);
            that.slow = 0.95 * that.slow + 0.05 * that.instant;
            that.clip = clipcount / input.length;
        };
    }

    SoundMeter.prototype.connectToSource = function(stream, callback) {
        console.log('SoundMeter connecting');
        try {
            this.mic = this.context.createMediaStreamSource(stream);
            this.mic.connect(this.script);
            // necessary to make sample run, but should not be.
            this.script.connect(this.context.destination);
            if (typeof callback !== 'undefined') {
                callback(null);
            }
        } catch (e) {
            console.error(e);
            if (typeof callback !== 'undefined') {
                callback(e);
            }
        }
    };
    SoundMeter.prototype.stop = function() {
        this.mic.disconnect();
        this.script.disconnect();
    };
</script>




<!-- get audio -->
<script>
    var instantValueDisplay = document.querySelector('#instant .value');
    var slowValueDisplay = document.querySelector('#slow .value');
    var clipValueDisplay = document.querySelector('#clip .value');

    // Put variables in global scope to make them available to the browser console.
    var constraints = window.constraints = {
        audio: true,
        video: false
    };


    startAudio();

    function startAudio(){
        try {
            window.AudioContext = window.AudioContext || window.webkitAudioContext;
            window.audioContext = new AudioContext();
        } catch (e) {
            alert('Web Audio API not supported.');
        }

        navigator.mediaDevices.getUserMedia(constraints).
        then(handleSuccess).catch(handleError);
    }



    function handleSuccess(stream) {
        window.stream = stream;
        var soundMeter = window.soundMeter = new SoundMeter(window.audioContext);
        soundMeter.connectToSource(stream, function(e) {
            if (e) {
                alert(e);
                return;
            }

            setInterval(function() {
                instantValueDisplay.innerHTML = soundMeter.instant.toFixed(2);
                slowValueDisplay.innerHTML = soundMeter.slow.toFixed(2);
                clipValueDisplay.innerHTML = soundMeter.clip;

                pow += soundMeter.instant.toFixed(2) * 50;
            }, 200);
        });
    }

    function handleError(error) {
        console.log('navigator.getUserMedia error: ', error);
    }




</script>








</body>
</html>


